{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from os.path import expanduser\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import text_to_word_sequence, Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tensorflow.keras.layers import Dense,Embedding,Input,Dropout,Conv1D\n",
    "from tensorflow.keras.layers import SpatialDropout1D, Flatten,LSTM, GlobalMaxPooling1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
      "id                                                                           \n",
      "00001cee341fdb12     -1            -1       -1      -1      -1             -1\n",
      "0000247867823ef7     -1            -1       -1      -1      -1             -1\n",
      "00013b17ad220c46     -1            -1       -1      -1      -1             -1\n",
      "00017563c3f7919a     -1            -1       -1      -1      -1             -1\n",
      "00017695ad8997eb     -1            -1       -1      -1      -1             -1\n",
      "0.41770912224804785 % of test is labelled\n",
      "(223549, 7) (89186, 1)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv',index_col=0)\n",
    "test = pd.read_csv('test.csv',index_col=0)\n",
    "test_labels = pd.read_csv('test_labels.csv',index_col=0)\n",
    "print(test_labels.head())\n",
    "labelled_test = test.join(test_labels)\n",
    "disclosed = labelled_test.toxic>-1\n",
    "print(disclosed .mean(),'% of test is labelled')\n",
    "train = train.append(labelled_test[disclosed])\n",
    "test = labelled_test[~disclosed][['comment_text']]\n",
    "print(train.shape,test.shape)\n",
    "train.to_csv('tc_train.csv')\n",
    "test.to_csv('tc_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0000997932d777bf</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000103f0d9cfb60f</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000113f07ec002fd</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001b41b1c6bb37e</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001d958c54c6e35</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       comment_text  toxic  \\\n",
       "id                                                                           \n",
       "0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "id                                                                      \n",
       "0000997932d777bf             0        0       0       0              0  \n",
       "000103f0d9cfb60f             0        0       0       0              0  \n",
       "000113f07ec002fd             0        0       0       0              0  \n",
       "0001b41b1c6bb37e             0        0       0       0              0  \n",
       "0001d958c54c6e35             0        0       0       0              0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('tc_train.csv',index_col=0)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(223549, 7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n"
     ]
    }
   ],
   "source": [
    "types = list(train)[1:]\n",
    "print(types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult',\n",
       "       'identity_hate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe5e77654d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train[types].mean().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " **********TOXIC COMMENTS********** \n",
      "\n",
      "COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK\n",
      "---- comment end ----\n",
      "Hey... what is it..\n",
      "@ | talk .\n",
      "What is it... an exclusive group of some WP TALIBANS...who are good at destroying, self-appointed purist who GANG UP any one who asks them questions abt their ANTI-SOCIAL and DESTRUCTIVE (non)-contribution at WP?\n",
      "\n",
      "Ask Sityush to clean up his behavior than issue me nonsensical warnings...\n",
      "---- comment end ----\n",
      "Bye! \n",
      "\n",
      "Don't look, come or think of comming back! Tosser.\n",
      "---- comment end ----\n",
      "\n",
      " **********SEVERE_TOXIC COMMENTS********** \n",
      "\n",
      "COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK\n",
      "---- comment end ----\n",
      "Stupid peace of shit stop deleting my stuff asshole go die and fall in a hole go to hell!\n",
      "---- comment end ----\n",
      "you are a stupid fuck \n",
      "\n",
      "and your mother's cunt stinks\n",
      "---- comment end ----\n",
      "\n",
      " **********OBSCENE COMMENTS********** \n",
      "\n",
      "COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK\n",
      "---- comment end ----\n",
      "You are gay or antisemmitian? \n",
      "\n",
      "Archangel WHite Tiger\n",
      "\n",
      "Meow! Greetingshhh!\n",
      "\n",
      "Uh, there are two ways, why you do erased my comment about WW2, that holocaust was brutally slaying of Jews and not gays/Gypsys/Slavs/anyone...\n",
      "\n",
      "1 - If you are anti-semitian, than shave your head bald and go to the skinhead meetings!\n",
      "\n",
      "2 - If you doubt words of the Bible, that homosexuality is a deadly sin, make a pentagram tatoo on your forehead go to the satanistic masses with your gay pals!\n",
      "\n",
      "3 - First and last warning, you fucking gay - I won't appreciate if any more nazi shwain would write in my page! I don't wish to talk to you anymore!\n",
      "\n",
      "Beware of the Dark Side!\n",
      "---- comment end ----\n",
      "FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!\n",
      "---- comment end ----\n",
      "\n",
      " **********THREAT COMMENTS********** \n",
      "\n",
      "Hi! I am back again!\n",
      "Last warning!\n",
      "Stop undoing my edits or die!\n",
      "---- comment end ----\n",
      "I think that your a Fagget get a oife and burn in Hell I hate you 'm sorry we cant have any more sex i'm running out of conndoms\n",
      "---- comment end ----\n",
      "I'm also a sock puppet of this account...SUPRISE!!\n",
      "-sincerely,\n",
      "            The man that will track you down from the Internet and kill you\n",
      "---- comment end ----\n",
      "\n",
      " **********INSULT COMMENTS********** \n",
      "\n",
      "COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK\n",
      "---- comment end ----\n",
      "You are gay or antisemmitian? \n",
      "\n",
      "Archangel WHite Tiger\n",
      "\n",
      "Meow! Greetingshhh!\n",
      "\n",
      "Uh, there are two ways, why you do erased my comment about WW2, that holocaust was brutally slaying of Jews and not gays/Gypsys/Slavs/anyone...\n",
      "\n",
      "1 - If you are anti-semitian, than shave your head bald and go to the skinhead meetings!\n",
      "\n",
      "2 - If you doubt words of the Bible, that homosexuality is a deadly sin, make a pentagram tatoo on your forehead go to the satanistic masses with your gay pals!\n",
      "\n",
      "3 - First and last warning, you fucking gay - I won't appreciate if any more nazi shwain would write in my page! I don't wish to talk to you anymore!\n",
      "\n",
      "Beware of the Dark Side!\n",
      "---- comment end ----\n",
      "FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!\n",
      "---- comment end ----\n",
      "\n",
      " **********IDENTITY_HATE COMMENTS********** \n",
      "\n",
      "You are gay or antisemmitian? \n",
      "\n",
      "Archangel WHite Tiger\n",
      "\n",
      "Meow! Greetingshhh!\n",
      "\n",
      "Uh, there are two ways, why you do erased my comment about WW2, that holocaust was brutally slaying of Jews and not gays/Gypsys/Slavs/anyone...\n",
      "\n",
      "1 - If you are anti-semitian, than shave your head bald and go to the skinhead meetings!\n",
      "\n",
      "2 - If you doubt words of the Bible, that homosexuality is a deadly sin, make a pentagram tatoo on your forehead go to the satanistic masses with your gay pals!\n",
      "\n",
      "3 - First and last warning, you fucking gay - I won't appreciate if any more nazi shwain would write in my page! I don't wish to talk to you anymore!\n",
      "\n",
      "Beware of the Dark Side!\n",
      "---- comment end ----\n",
      "A pair of jew-hating weiner nazi schmucks.\n",
      "---- comment end ----\n",
      "I think that your a Fagget get a oife and burn in Hell I hate you 'm sorry we cant have any more sex i'm running out of conndoms\n",
      "---- comment end ----\n"
     ]
    }
   ],
   "source": [
    "for t in types:\n",
    "    print('\\n','*'*10+(t+' comments').upper()+'*'*10,'\\n')\n",
    "    for c in train.comment_text[train[t]==1][:3]:\n",
    "        print(c)\n",
    "        print('---- comment end ----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embedding index from file in .txt format. First line contains \n",
    "# dictionary size and embedding dim. Fields are space separated\n",
    "def get_embeddings(file_name):\n",
    "    embeddings_index = {}\n",
    "    with open(file_name, encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            values = line.rstrip().split(' ')\n",
    "            if len(values) > 2:\n",
    "                embeddings_index[values[0]] = np.asarray(values[1:], dtype=\"float32\")\n",
    "    return embeddings_index\n",
    "\n",
    "embeddings_index = get_embeddings('crawl-300d-2M.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>comment_clean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0000997932d777bf</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000103f0d9cfb60f</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d'aww  he matches this background colour i'm s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000113f07ec002fd</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man  i'm really not trying to edit war  it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001b41b1c6bb37e</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>more i can't make any real suggestions on im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001d958c54c6e35</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>you  sir  are my hero  any chance you remember...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       comment_text  toxic  \\\n",
       "id                                                                           \n",
       "0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                  severe_toxic  obscene  threat  insult  identity_hate  \\\n",
       "id                                                                       \n",
       "0000997932d777bf             0        0       0       0              0   \n",
       "000103f0d9cfb60f             0        0       0       0              0   \n",
       "000113f07ec002fd             0        0       0       0              0   \n",
       "0001b41b1c6bb37e             0        0       0       0              0   \n",
       "0001d958c54c6e35             0        0       0       0              0   \n",
       "\n",
       "                                                      comment_clean  \n",
       "id                                                                   \n",
       "0000997932d777bf  explanation why the edits made under my userna...  \n",
       "000103f0d9cfb60f  d'aww  he matches this background colour i'm s...  \n",
       "000113f07ec002fd  hey man  i'm really not trying to edit war  it...  \n",
       "0001b41b1c6bb37e    more i can't make any real suggestions on im...  \n",
       "0001d958c54c6e35  you  sir  are my hero  any chance you remember...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "trans_table = str.maketrans({key: ' ' for key in string.digits + '\\r\\n' +\n",
    "                             string.punctuation.replace(\"\\'\",'')})\n",
    "def preprocess(text):\n",
    "    return ' '.join(text.lower().translate(trans_table).split(' '))\n",
    "\n",
    "train['comment_clean'] = train.comment_text.apply(preprocess)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the vocabulary of words occurred more than 5\n",
      "45259 top words\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "UNKNOWN_PROXY = 'unknown'\n",
    "MIN_WORD_OCCURRENCE = 5\n",
    "\n",
    "print(\"Creating the vocabulary of words occurred more than\", MIN_WORD_OCCURRENCE)\n",
    "vectorizer = CountVectorizer(lowercase=False, token_pattern=\"\\S+\", \n",
    "                             min_df=MIN_WORD_OCCURRENCE)\n",
    "vectorizer.fit(train.comment_clean)\n",
    "\n",
    "top_words = set(vectorizer.vocabulary_.keys())\n",
    "top_words.add(UNKNOWN_PROXY)\n",
    "print(len(top_words),'top words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras_preprocessing.text.Tokenizer object at 0x7fe5ccd2cf50>\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(filters=\"\")\n",
    "tokenizer.fit_on_texts(train.comment_clean)\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280518\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('the', 1),\n",
       " ('to', 2),\n",
       " ('of', 3),\n",
       " ('and', 4),\n",
       " ('a', 5),\n",
       " ('you', 6),\n",
       " ('i', 7),\n",
       " ('is', 8),\n",
       " ('that', 9),\n",
       " ('in', 10),\n",
       " ('it', 11),\n",
       " ('for', 12),\n",
       " ('this', 13),\n",
       " ('not', 14),\n",
       " ('on', 15),\n",
       " ('be', 16)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print(len(word_index))\n",
    "list(word_index.items())[:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 2 sequences in `seq`:  [[676, 77, 1, 133, 130, 177, 30, 666, 4436, 11406, 1126, 85, 349, 51, 2184, 12587, 50, 6354, 15, 59, 2567, 148, 7, 2795, 33, 116, 1196, 15967, 2453, 4, 47, 60, 247, 1, 359, 31, 1, 41, 27, 143, 71, 3503, 89], [121402, 52, 2765, 13, 466, 3656, 71, 4530, 2696, 21, 93, 41, 968, 196]]\n",
      "\n",
      "Shape of `data`:  (223549, 50)\n",
      "\n",
      "First prepared text in `data`: [  676    77     1   133   130   177    30   666  4436 11406  1126    85\n",
      "   349    51  2184 12587    50  6354    15    59  2567   148     7  2795\n",
      "    33   116  1196 15967  2453     4    47    60   247     1   359    31\n",
      "     1    41    27   143    71  3503    89     0     0     0     0     0\n",
      "     0     0]\n"
     ]
    }
   ],
   "source": [
    "MAX_SEQUENCE_LENGTH = 50\n",
    "seq = tokenizer.texts_to_sequences(train.comment_clean)\n",
    "data = pad_sequences(seq,maxlen=MAX_SEQUENCE_LENGTH,padding='post',\n",
    "                     truncating='post')\n",
    "with open('comments.pkl','wb') as f: pickle.dump(data, f, -1)\n",
    "\n",
    "print('\\nFirst 2 sequences in `seq`: ',seq[:2])\n",
    "print('\\nShape of `data`: ',data.shape)\n",
    "print('\\nFirst prepared text in `data`:',data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dim = len(next(iter(embeddings_index.values())))\n",
    "embeddings_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embedding matrix\n",
    "def get_embedding_matrix(word_index,embeddings_index):\n",
    "    nb_words = len(word_index) + 1 # +1 since min(word_index.values())=1\n",
    "    embedding_matrix = np.zeros((nb_words,embeddings_dim))\n",
    "    unknown = 0\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is None: unknown += 1\n",
    "        else: embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix, unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160113 unknown words\n"
     ]
    }
   ],
   "source": [
    "# Create embedding_layer and save it.\n",
    "def make_save_emb_layer(word_index,embeddings_index,layer_file_name):\n",
    "    embedding_matrix,unknown = get_embedding_matrix(word_index,embeddings_index)\n",
    "    embedding_layer = Embedding(embedding_matrix.shape[0],embedding_matrix.shape[1],\n",
    "                                weights=[embedding_matrix],trainable=False)\n",
    "    with open(layer_file_name,'wb') as f: \n",
    "        pickle.dump(embedding_layer, f, -1)\n",
    "    return unknown\n",
    "\n",
    "EMBEDDING_LAYER_FILE = 'toxic_comments_embed_layer.pkl'\n",
    "print(make_save_emb_layer(word_index,embeddings_index,EMBEDDING_LAYER_FILE),\n",
    "      'unknown words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: \n",
      " id\n",
      "0000997932d777bf    000000\n",
      "000103f0d9cfb60f    000000\n",
      "000113f07ec002fd    000000\n",
      "0001b41b1c6bb37e    000000\n",
      "0001d958c54c6e35    000000\n",
      "dtype: object\n",
      "\n",
      "Counts of labels: \n",
      " 000000    201081\n",
      "100000      7376\n",
      "101010      5732\n",
      "101000      2612\n",
      "100010      1754\n",
      "111010      1165\n",
      "101011       979\n",
      "111011       381\n",
      "001000       366\n",
      "000010       365\n",
      "100011       215\n",
      "100001       203\n",
      "101110       196\n",
      "001010       196\n",
      "111000       186\n",
      "100100       163\n",
      "111110        88\n",
      "101111        81\n",
      "000001        68\n",
      "101001        55\n",
      "111111        45\n",
      "110000        41\n",
      "000011        32\n",
      "000100        27\n",
      "100110        25\n",
      "001011        19\n",
      "101100        17\n",
      "110010        14\n",
      "110100        11\n",
      "100101        11\n",
      "111100         8\n",
      "111001         7\n",
      "110011         7\n",
      "110101         5\n",
      "rare           5\n",
      "000110         4\n",
      "100111         3\n",
      "001001         3\n",
      "110001         3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# convert each vector of labels to the string\n",
    "labels = train[types].astype(str).apply(lambda x: ''.join(x),axis=1)\n",
    "print('Labels: \\n',labels.head())\n",
    "# aggregate rare combinations if any\n",
    "count = labels.value_counts()\n",
    "rare = count.index[count<=2]\n",
    "labels[np.isin(labels.values,rare)] = 'rare'\n",
    "print('\\nCounts of labels: \\n',labels.value_counts())\n",
    "train_index, val_index = train_test_split(list(range(data.shape[0])), test_size=0.2, \n",
    "                                      stratify = labels, random_state=0)\n",
    "# save train and validation indices for further calculations\n",
    "fname = 'train_val_split.pkl'\n",
    "with open(fname, 'wb') as f: pickle.dump([train_index, val_index], f, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    input_layer = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
    "    x = embedding_layer(input_layer)\n",
    "    x = SpatialDropout1D(0.5)(x)\n",
    "    x = LSTM(10, return_sequences=True)(x)\n",
    "    x = Conv1D(5, kernel_size=2, padding=\"valid\")(x)\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(.2)(x)\n",
    "    output_layer = Dense(6, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=Adam())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(EMBEDDING_LAYER_FILE, 'rb') as f: embedding_layer = pickle.load(f)\n",
    "with open('comments.pkl', 'rb') as f: data = pickle.load(f)   \n",
    "\n",
    "X_train = data[train_index]\n",
    "X_val = data[val_index]\n",
    "\n",
    "y_train = train.iloc[train_index][['toxic','severe_toxic','obscene','threat','insult','identity_hate']]\n",
    "y_val = train.iloc[val_index][['toxic','severe_toxic','obscene','threat','insult','identity_hate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 50)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 50, 300)           84155700  \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 50, 300)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 50, 10)            12440     \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 49, 5)             105       \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 5)                 20        \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 36        \n",
      "=================================================================\n",
      "Total params: 84,168,301\n",
      "Trainable params: 12,591\n",
      "Non-trainable params: 84,155,710\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "best_model_path = 'best_model.h5'\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "early_stopping = EarlyStopping(patience=2)\n",
    "model_checkpoint = ModelCheckpoint(best_model_path,\n",
    "                                   save_best_only=True, save_weights_only=True)\n",
    "\n",
    "model = get_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "350/350 - 28s - loss: 0.0648 - val_loss: 0.0538\n",
      "Epoch 2/100\n",
      "350/350 - 26s - loss: 0.0645 - val_loss: 0.0536\n",
      "Epoch 3/100\n",
      "350/350 - 28s - loss: 0.0641 - val_loss: 0.0531\n",
      "Epoch 4/100\n",
      "350/350 - 29s - loss: 0.0633 - val_loss: 0.0531\n",
      "Epoch 5/100\n",
      "350/350 - 28s - loss: 0.0628 - val_loss: 0.0529\n",
      "Epoch 6/100\n",
      "350/350 - 28s - loss: 0.0621 - val_loss: 0.0536\n",
      "Epoch 7/100\n",
      "350/350 - 28s - loss: 0.0618 - val_loss: 0.0527\n",
      "Epoch 8/100\n",
      "350/350 - 29s - loss: 0.0612 - val_loss: 0.0525\n",
      "Epoch 9/100\n",
      "350/350 - 29s - loss: 0.0604 - val_loss: 0.0525\n",
      "Epoch 10/100\n",
      "350/350 - 28s - loss: 0.0601 - val_loss: 0.0525\n",
      "Epoch 11/100\n",
      "350/350 - 28s - loss: 0.0595 - val_loss: 0.0524\n",
      "Epoch 12/100\n",
      "350/350 - 28s - loss: 0.0595 - val_loss: 0.0517\n",
      "Epoch 13/100\n",
      "350/350 - 28s - loss: 0.0593 - val_loss: 0.0518\n",
      "Epoch 14/100\n",
      "350/350 - 28s - loss: 0.0589 - val_loss: 0.0517\n",
      "Epoch 15/100\n",
      "350/350 - 28s - loss: 0.0583 - val_loss: 0.0521\n",
      "Epoch 16/100\n",
      "350/350 - 28s - loss: 0.0580 - val_loss: 0.0515\n",
      "Epoch 17/100\n",
      "350/350 - 29s - loss: 0.0579 - val_loss: 0.0512\n",
      "Epoch 18/100\n",
      "350/350 - 28s - loss: 0.0575 - val_loss: 0.0512\n",
      "Epoch 19/100\n",
      "350/350 - 30s - loss: 0.0573 - val_loss: 0.0511\n",
      "Epoch 20/100\n",
      "350/350 - 29s - loss: 0.0571 - val_loss: 0.0511\n",
      "Epoch 21/100\n",
      "350/350 - 28s - loss: 0.0573 - val_loss: 0.0511\n",
      "Epoch 22/100\n",
      "350/350 - 28s - loss: 0.0569 - val_loss: 0.0509\n",
      "Epoch 23/100\n",
      "350/350 - 28s - loss: 0.0567 - val_loss: 0.0513\n",
      "Epoch 24/100\n",
      "350/350 - 28s - loss: 0.0567 - val_loss: 0.0514\n",
      "validation AUC 0.977071325582917\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, y_train,validation_data=(X_val, y_val),\n",
    "                 epochs=100, batch_size=BATCH_SIZE, shuffle=True, verbose=2,\n",
    "                 callbacks=[model_checkpoint, early_stopping])\n",
    "model.load_weights(best_model_path)\n",
    "val_pred = model.predict(X_val, batch_size=BATCH_SIZE, verbose=0)\n",
    "print('validation AUC',roc_auc_score(y_val, val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89186, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00001cee341fdb12</th>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000247867823ef7</th>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00013b17ad220c46</th>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00017563c3f7919a</th>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00017695ad8997eb</th>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       comment_text\n",
       "id                                                                 \n",
       "00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
       "0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
       "00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
       "00017563c3f7919a  :If you have a look back at the source, the in...\n",
       "00017695ad8997eb          I don't anonymously edit articles at all."
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('tc_test.csv',index_col=0)\n",
    "print(test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['comment_text'], dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['comment_clean'] = test.comment_text.apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seq = tokenizer.texts_to_sequences(test.comment_clean)\n",
    "test_data = pad_sequences(test_seq,maxlen=MAX_SEQUENCE_LENGTH,padding='post',\n",
    "                         truncating='post')\n",
    "with open('test_comments.pkl','wb') as f: pickle.dump(data, f, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model.predict(test_data, batch_size=BATCH_SIZE, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.46724236e-01, 4.46123391e-01, 9.24213469e-01, 1.82200134e-01,\n",
       "        8.91353726e-01, 3.87172103e-01],\n",
       "       [6.25431538e-04, 3.29301729e-05, 5.84352638e-05, 6.94514601e-05,\n",
       "        9.59684985e-05, 5.94568955e-05],\n",
       "       [3.67671251e-04, 4.13052257e-05, 3.94473391e-05, 1.20243414e-04,\n",
       "        6.90096931e-05, 7.77454552e-05],\n",
       "       ...,\n",
       "       [5.98579645e-04, 4.06227555e-05, 5.88466974e-05, 9.87384774e-05,\n",
       "        1.24692917e-04, 7.38880481e-05],\n",
       "       [9.35882330e-04, 7.37655428e-05, 1.05456573e-04, 1.59978867e-04,\n",
       "        1.92344189e-04, 1.29759312e-04],\n",
       "       [7.11458325e-01, 3.01536322e-02, 4.71978396e-01, 9.70825553e-03,\n",
       "        4.02154744e-01, 2.35576034e-02]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.DataFrame(test_pred, index=test.index)\n",
    "out.columns = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89186, 6)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['00001cee341fdb12', '0000247867823ef7', '00013b17ad220c46',\n",
       "       '00017563c3f7919a', '00017695ad8997eb', '00024115d4cbde0f',\n",
       "       '00025358d4737918', '00026d1092fe71cc', '0002eadc3b301559',\n",
       "       '0003806b11932181',\n",
       "       ...\n",
       "       'fff8ef316d0c6990', 'fff9fa508f400ee6', 'fffa3fae1890b40a',\n",
       "       'fffc2b34bbe61c8d', 'fffc489742ffe69b', 'fffcd0960ee309b5',\n",
       "       'fffd7a9a6eb32c16', 'fffda9e8d6fafa9e', 'fffe8f1340a79fc2',\n",
       "       'ffffce3fb183ee80'],\n",
       "      dtype='object', name='id', length=89186)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.to_csv('tc_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89186, 2)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(223549, 8)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>comment_clean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0000997932d777bf</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000103f0d9cfb60f</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d'aww  he matches this background colour i'm s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000113f07ec002fd</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man  i'm really not trying to edit war  it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001b41b1c6bb37e</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>more i can't make any real suggestions on im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001d958c54c6e35</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>you  sir  are my hero  any chance you remember...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       comment_text  toxic  \\\n",
       "id                                                                           \n",
       "0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                  severe_toxic  obscene  threat  insult  identity_hate  \\\n",
       "id                                                                       \n",
       "0000997932d777bf             0        0       0       0              0   \n",
       "000103f0d9cfb60f             0        0       0       0              0   \n",
       "000113f07ec002fd             0        0       0       0              0   \n",
       "0001b41b1c6bb37e             0        0       0       0              0   \n",
       "0001d958c54c6e35             0        0       0       0              0   \n",
       "\n",
       "                                                      comment_clean  \n",
       "id                                                                   \n",
       "0000997932d777bf  explanation why the edits made under my userna...  \n",
       "000103f0d9cfb60f  d'aww  he matches this background colour i'm s...  \n",
       "000113f07ec002fd  hey man  i'm really not trying to edit war  it...  \n",
       "0001b41b1c6bb37e    more i can't make any real suggestions on im...  \n",
       "0001d958c54c6e35  you  sir  are my hero  any chance you remember...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>comment_clean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00001cee341fdb12</th>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "      <td>yo bitch ja rule is more succesful then you'll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000247867823ef7</th>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "      <td>from rfc       the title is fine as it is  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00013b17ad220c46</th>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "      <td>sources         zawe ashton on lapland...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00017563c3f7919a</th>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "      <td>if you have a look back at the source  the in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00017695ad8997eb</th>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "      <td>i don't anonymously edit articles at all</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       comment_text  \\\n",
       "id                                                                    \n",
       "00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...   \n",
       "0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...   \n",
       "00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...   \n",
       "00017563c3f7919a  :If you have a look back at the source, the in...   \n",
       "00017695ad8997eb          I don't anonymously edit articles at all.   \n",
       "\n",
       "                                                      comment_clean  \n",
       "id                                                                   \n",
       "00001cee341fdb12  yo bitch ja rule is more succesful then you'll...  \n",
       "0000247867823ef7     from rfc       the title is fine as it is  ...  \n",
       "00013b17ad220c46          sources         zawe ashton on lapland...  \n",
       "00017563c3f7919a   if you have a look back at the source  the in...  \n",
       "00017695ad8997eb          i don't anonymously edit articles at all   "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00001cee341fdb12</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.946724</td>\n",
       "      <td>0.446123</td>\n",
       "      <td>0.924213</td>\n",
       "      <td>0.182200</td>\n",
       "      <td>0.891354</td>\n",
       "      <td>0.387172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000247867823ef7</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00013b17ad220c46</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00017563c3f7919a</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.007346</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.001026</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.000561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00017695ad8997eb</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.002432</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>0.000287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id     toxic  severe_toxic   obscene  \\\n",
       "id                                                                     \n",
       "00001cee341fdb12  00001cee341fdb12  0.946724      0.446123  0.924213   \n",
       "0000247867823ef7  0000247867823ef7  0.000625      0.000033  0.000058   \n",
       "00013b17ad220c46  00013b17ad220c46  0.000368      0.000041  0.000039   \n",
       "00017563c3f7919a  00017563c3f7919a  0.007346      0.000357  0.001026   \n",
       "00017695ad8997eb  00017695ad8997eb  0.002432      0.000178  0.000330   \n",
       "\n",
       "                    threat    insult  identity_hate  \n",
       "id                                                   \n",
       "00001cee341fdb12  0.182200  0.891354       0.387172  \n",
       "0000247867823ef7  0.000069  0.000096       0.000059  \n",
       "00013b17ad220c46  0.000120  0.000069       0.000078  \n",
       "00017563c3f7919a  0.000452  0.001548       0.000561  \n",
       "00017695ad8997eb  0.000327  0.000526       0.000287  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89186, 7)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
